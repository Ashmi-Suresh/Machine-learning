{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgFXKWl_g6Ar"
   },
   "source": [
    "Project 3: (10 points)\n",
    "your total (50 points) will divided by 5 to get 10 points for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejBaMIsShJNl"
   },
   "source": [
    "\n",
    "In this project, we will focus on the preprocessing step before building the model.\n",
    "\n",
    "We will prepare data before making a Market basket analysis, which is an algorithm originally designed to help retailers understand and improve their businesses. \n",
    "\n",
    "Also, we will do some important preprocessing step before building an unsupervised model for Customer Segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da1OV543hvGv"
   },
   "source": [
    "### Market Basket Analysis\n",
    "---\n",
    "Imagine you work for a retailer that sells dozens of products and your boss comes to you and asks the following questions:\n",
    "\n",
    "* What products are purchased together most frequently?\n",
    "* How should the products be organized and positioned in the store?\n",
    "* How do we identify the best products to discount via coupons?\n",
    "---\n",
    "##### You might reasonably respond with complete bewilderment, as those questions are very diverse and do not immediately seem answerable using a single algorithm and dataset. However, the answer to all those questions and many more is market basket analysis. \n",
    "--\n",
    "### Dataset:\n",
    "you can find the dataset on Canvas under Dataset section: \"Online Retail.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwcIjv_FkKq8"
   },
   "source": [
    "### Steps to do:\n",
    "\n",
    "1- Open a Jupyter notebook.\n",
    "\n",
    "2- Install the following libraries, if not installed, and then import them:\n",
    "* matplotlib.pyplot, which is used to plot the results of the models.\n",
    "* mlxtend.frequent_patterns, which is used to run the models; \n",
    "* mlxtend.preprocessing, which is used to encode and prep the data for the models;\n",
    "* numpy, which is used to work with arrays; \n",
    "* pandas, which is used to work with DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ashmibidrupanesuresh/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dCLgo8JqkQMK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlxtend.frequent_patterns\n",
    "import mlxtend.preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWG1Fz66kW7q"
   },
   "source": [
    "3- Loading Data ( 1 point)\n",
    "\n",
    "Load and view online retail dataset.Once you have downloaded the dataset, save it and note the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8mie-OzSkeNd"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "online_retail_df = pd.read_excel(\"Online Retail.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMTXKPNMkksH"
   },
   "source": [
    "4- Print out the first 10 rows of the DataFrame. ( 1 point)\n",
    "\n",
    "Notice that the data contains some columns that will not be relevant to market basket analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JzDdJ6Zlknig"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
      "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
      "7    536366     22633               HAND WARMER UNION JACK         6   \n",
      "8    536366     22632            HAND WARMER RED POLKA DOT         6   \n",
      "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "5 2010-12-01 08:26:00       7.65     17850.0  United Kingdom  \n",
      "6 2010-12-01 08:26:00       4.25     17850.0  United Kingdom  \n",
      "7 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "8 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
      "9 2010-12-01 08:34:00       1.69     13047.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "print(online_retail_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjzSRKYQkqny"
   },
   "source": [
    "5- Print out the data type for each column in the DataFrame. (1 point)\n",
    "\n",
    "This information will come in handy when trying to perform specific cleaning tasks. Columns need to be of the correct type in order for filtering and computing to execute as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xQumi7oWksza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID            float64\n",
      "Country                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "print(online_retail_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwxWJbQskwAM"
   },
   "source": [
    "6- Get and print the dimensions of the DataFrame, as well as the number of unique invoice numbers and customer identifications (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9fecqG66kyUM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541909, 8)\n",
      "Number of rows: 541909\n",
      "Number of columns: 8\n",
      "Number of unique invoice numbers: 25900\n",
      "Number of unique customer identifications: 4372\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "print(online_retail_df.shape)\n",
    "num_rows, num_cols = online_retail_df.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")\n",
    "\n",
    "#To get and print the number of unique invoice numbers and customer identifications\n",
    "num_unique_invoices = online_retail_df['InvoiceNo'].nunique()\n",
    "num_unique_customers = online_retail_df['CustomerID'].nunique()\n",
    "print(f\"Number of unique invoice numbers: {num_unique_invoices}\")\n",
    "print(f\"Number of unique customer identifications: {num_unique_customers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W8ph75ck1lu"
   },
   "source": [
    "7- Data Cleaning and Formatting:\n",
    "\n",
    "a. Create an indicator column stipulating whether the invoice number begins with \"C\". Called the column \"IsCPresent\" ( 1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h66BgH-gk4o7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country IsCPresent  \n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom        NaN  \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom        NaN  \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom        NaN  \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom        NaN  \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom        NaN  \n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "online_retail_df['IsCPresent'] = online_retail_df['InvoiceNo'].str.startswith('C')\n",
    "\n",
    "# Print the first few rows of the DataFrame with the new indicator column\n",
    "print(online_retail_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29SGnBKUk5vx"
   },
   "source": [
    "b. (3 points)\n",
    "- Filter out all transactions having either zero or a negative number of items (in other words, items were returned), \n",
    "- Remove all invoice numbers starting with \"C\" using the column created in previous step \n",
    "- Subset the DataFrame down to InvoiceNo and Description\n",
    "- Drop all rows with at least one missing value. \n",
    "- Rename the DataFrame online1 and print out the first 10 rows of the filtered DataFrame, online1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pjoR-GvqolGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530693, 2)\n",
      "  InvoiceNo                          Description\n",
      "0    536365   WHITE HANGING HEART T-LIGHT HOLDER\n",
      "1    536365                  WHITE METAL LANTERN\n",
      "2    536365       CREAM CUPID HEARTS COAT HANGER\n",
      "3    536365  KNITTED UNION FLAG HOT WATER BOTTLE\n",
      "4    536365       RED WOOLLY HOTTIE WHITE HEART.\n",
      "5    536365         SET 7 BABUSHKA NESTING BOXES\n",
      "6    536365    GLASS STAR FROSTED T-LIGHT HOLDER\n",
      "7    536366               HAND WARMER UNION JACK\n",
      "8    536366            HAND WARMER RED POLKA DOT\n",
      "9    536367        ASSORTED COLOUR BIRD ORNAMENT\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# Filter out transactions with zero or negative number of items\n",
    "online_retail_df = online_retail_df[online_retail_df['Quantity'] > 0]\n",
    "\n",
    "# Convert 'InvoiceNo' column to string type\n",
    "online_retail_df['InvoiceNo'] = online_retail_df['InvoiceNo'].astype(str)\n",
    "# Remove invoice numbers starting with \"C\"\n",
    "online_retail_df = online_retail_df[~online_retail_df['InvoiceNo'].str.startswith('C')]\n",
    "\n",
    "# Subset the DataFrame to include only 'InvoiceNo' and 'Description'\n",
    "online_retail_df = online_retail_df[['InvoiceNo', 'Description']]\n",
    "\n",
    "# Drop rows with missing values\n",
    "online_retail_df.dropna(inplace=True)\n",
    "\n",
    "# Rename the filtered DataFrame as 'online1'\n",
    "online1 = online_retail_df\n",
    "print(online1.shape)\n",
    "# Print out the first 10 rows of the filtered DataFrame\n",
    "print(online1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKviaPYklDWn"
   },
   "source": [
    "c. Approximately, how many rows and invoice numbers have already removed? ( 2 points)\n",
    "\n",
    "--\n",
    "### Edit to write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DDD6mTJRlFus"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately number of rows removed: 11216\n",
      "Approximately number of invoice numbers removed: 5764\n"
     ]
    }
   ],
   "source": [
    "#write your code here to prove your answer:\n",
    "\n",
    "filtered_shape = online1.shape\n",
    "\n",
    "# Calculate the approximate number of rows and invoice numbers that have been removed\n",
    "rows_removed = num_rows - filtered_shape[0]\n",
    "invoices_removed = num_unique_invoices - online1['InvoiceNo'].nunique()\n",
    "\n",
    "# Print the approximate number of rows and invoice numbers that have been removed\n",
    "print(f\"Approximately number of rows removed: {rows_removed}\")\n",
    "print(f\"Approximately number of invoice numbers removed: {invoices_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUjagck4lXNV"
   },
   "source": [
    "d. (2 points)\n",
    "- Extract the invoice numbers from the DataFrame as a list. \n",
    "- Remove duplicate elements to create a list of unique invoice numbers. \n",
    "- Confirm that the process was successful by printing the length of the list of unique invoice numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2zBLgtfKla5p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique invoice numbers list: 20136\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "invoice_numbers = online1['InvoiceNo'].tolist()\n",
    "\n",
    "# Remove duplicate elements to create a list of unique invoice numbers\n",
    "unique_invoice_numbers = list(set(invoice_numbers))\n",
    "\n",
    "# Confirm the success by printing the length of the list of unique invoice numbers\n",
    "print(f\"Length of unique invoice numbers list: {len(unique_invoice_numbers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bgt43yxElen8"
   },
   "source": [
    "e. Take the list from step d and cut it to only include the first 5,000 elements. Print out the length of the new list to confirm that it is, in fact, the expected length of 5,000( 1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CZAyLfinliQx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first 5000 invoice numbers list: 5000\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# Extract the first 5,000 elements from the list of unique invoice numbers\n",
    "first_5000_invoice_numbers = unique_invoice_numbers[:5000]\n",
    "\n",
    "# Print out the length of the new list\n",
    "print(f\"Length of first 5000 invoice numbers list: {len(first_5000_invoice_numbers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVgjErInlmQH"
   },
   "source": [
    "f. Filter the online1 DataFrame down by only keeping the invoice numbers in the list from step e and print out the first 10 rows of online1( 1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1OVhCiwglpsD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    InvoiceNo                        Description\n",
      "7      536366             HAND WARMER UNION JACK\n",
      "8      536366          HAND WARMER RED POLKA DOT\n",
      "46     536371    PAPER CHAIN KIT 50'S CHRISTMAS \n",
      "82     536376  HOT WATER BOTTLE TEA AND SYMPATHY\n",
      "83     536376   RED HANGING HEART T-LIGHT HOLDER\n",
      "168    536385   SET 3 WICKER OVAL BASKETS W LIDS\n",
      "169    536385             JAM MAKING SET PRINTED\n",
      "170    536385           JAM MAKING SET WITH JARS\n",
      "171    536385        JUMBO BAG DOLLY GIRL DESIGN\n",
      "172    536385      TRADITIONAL CHRISTMAS RIBBONS\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "invoice_numbers_to_keep = first_5000_invoice_numbers  # Replace with your list from step e\n",
    "online1 = online1[online1['InvoiceNo'].isin(invoice_numbers_to_keep)]\n",
    "\n",
    "# Print out the first 10 rows of the filtered DataFrame\n",
    "print(online1.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0qukXPhlrGY"
   },
   "source": [
    "g. Print out the dimensions of the DataFrame (online1) and the number of unique invoice numbers to confirm that the filtering and cleaning process was successful (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jGEjdeV_lwdy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of online1 DataFrame: (134916, 2)\n",
      "Number of unique invoice numbers in online1: 5000\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# Print out the dimensions of the filtered DataFrame\n",
    "print(f\"Dimensions of online1 DataFrame: {online1.shape}\")\n",
    "\n",
    "# Get the number of unique invoice numbers in the filtered DataFrame\n",
    "unique_invoice_numbers_online1 = online1['InvoiceNo'].nunique()\n",
    "print(f\"Number of unique invoice numbers in online1: {unique_invoice_numbers_online1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELrV7XgAl1or"
   },
   "source": [
    "h. Transform the data in online1 into the aforementioned list of lists called invoice_item_list. The process for doing this is to iterate over the unique invoice numbers and, at each iteration, extract the item descriptions as a list and append that list to the larger invoice_item_list list. Print out elements one through four of the list (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3TjwnQ1ouSB"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# Initialize an empty list to store the invoice_item_list\n",
    "invoice_item_list = []\n",
    "\n",
    "# Iterate over the unique invoice numbers in online1\n",
    "for invoice_number in online1['InvoiceNo'].unique():\n",
    "    # Extract the item descriptions as a list for the current invoice\n",
    "    item_descriptions = online1[online1['InvoiceNo'] == invoice_number]['Description'].tolist()\n",
    "    # Append the item_descriptions list to the invoice_item_list\n",
    "    invoice_item_list.append(item_descriptions)\n",
    "\n",
    "# Print out elements one through four of the invoice_item_list\n",
    "print(\"Elements one through four of invoice_item_list:\")\n",
    "print(invoice_item_list[0])\n",
    "print(invoice_item_list[1])\n",
    "print(invoice_item_list[2])\n",
    "print(invoice_item_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDI2Nt9l8yK"
   },
   "source": [
    "8- Data Encoding\n",
    "\n",
    "While cleaning the data is crucial, the most important part of the data preparation process is molding the data into the correct form. Before running the models, the data, currently in the list of lists form, needs to be encoded and recast as a DataFrame.\n",
    "\n",
    "To do this, we will leverage TransactionEncoder from the preprocessing module of mlxtend. The output from the encoder is a multidimensional array, where each row is the length of the total number of unique items in the transaction dataset and the elements are Boolean variables, indicating whether that particular item is linked to the invoice number that row represents. With the data encoded, we can recast it as a DataFrame where the rows are the invoice numbers and the columns are the unique items in the transaction dataset.\n",
    "\n",
    "The data encoding will be done using mlxtend, but if you wish to encode the data without using a package, you are free.\n",
    "\n",
    "More info about mlxtend in the link: https://rasbt.github.io/mlxtend/\n",
    "\n",
    "a. Initialize and fit the transaction encoder. Print out an example of the resulting data. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8JKo9ecmC5o"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "encoder = TransactionEncoder()\n",
    "\n",
    "# Fit the encoder to the invoice_item_list data\n",
    "encoder.fit(invoice_item_list)\n",
    "\n",
    "# Transform the invoice_item_list data into a multidimensional array of Boolean variables\n",
    "encoded_data = encoder.transform(invoice_item_list)\n",
    "\n",
    "# Print out an example of the resulting encoded data\n",
    "print(\"Example of the resulting encoded data:\")\n",
    "print(encoded_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3ElUp84mF_4"
   },
   "source": [
    "b. Recast the encoded array as a DataFrame named online_encoder_df. Print the predefined subset of the DataFrame that features both True and False values (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oX9c8MZ4l5BM"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "online_encoder_df = pd.DataFrame(encoded_data, columns=encoder.columns_)\n",
    "\n",
    "# Print the subset of the DataFrame that features both True and False values\n",
    "subset_df = online_encoder_df[(online_encoder_df == True).any(axis=1) & (online_encoder_df == False).any(axis=1)]\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDG6mHIao4Es"
   },
   "source": [
    "c. Print out the dimensions of the encoded DataFrame. It should have 5,000 rows because the data used to generate it was previously filtered down to 5,000 unique invoice numbers. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbneZjbKk__P"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "print(\"Dimensions of encoded DataFrame: \", online_encoder_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDepnejUpB7u"
   },
   "source": [
    "#### The data is now prepared for modeling.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7gpFsB0pbvv"
   },
   "source": [
    "### Wholesale Data\n",
    "\n",
    "we will analyze a dataset containing data on various customers' annual spending amounts (reported in monetary units) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\n",
    "\n",
    "--\n",
    "### Dataset:\n",
    "you can find the dataset on Canvas under Dataset section: \"wholesale_customers_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T00:25:36.756020Z",
     "start_time": "2018-01-09T00:25:34.246895Z"
    },
    "id": "7cLIlYcgY9Rm"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.random import uniform, multivariate_normal, rand, randn, seed\n",
    "from itertools import repeat\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.stats import jarque_bera, normaltest\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzbwQeO4aKVm"
   },
   "source": [
    "1. Load the wholesale customers dataset (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AajRmspuZRC9"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wholesale_customers_df = pd.read_csv('wholesale_customers_data.csv')\n",
    "wholesale_customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eQ2Jd7EY9Rr"
   },
   "source": [
    "2. Drop Channel & Region and print the current columns ( 1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h_evyZTkY9Rr"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wholesale_customers_df = wholesale_customers_df.drop(['Channel', 'Region'], axis=1)\n",
    "\n",
    "# Print out the current columns in the DataFrame\n",
    "print(wholesale_customers_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvnWgHF9asOQ"
   },
   "source": [
    "### Data Exploration:\n",
    "\n",
    "You will begin exploring the data through visualizations and code to understand how each feature is related to the others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTctTSJ6a8hK"
   },
   "source": [
    "3. Show a statistical summary for each of the above product categories. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11D_uRrca-Yw"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "product_categories_summary = wholesale_customers_df.describe()\n",
    "\n",
    "# Print out the statistical summary\n",
    "print(product_categories_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIqPMCGbetH_"
   },
   "source": [
    "4. Show a visual representation of the distribution of each feature in the data.using histogram and normal probability plot. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp5YvpMeeVWs"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "from scipy.stats import probplot\n",
    "# Loop through columns and create plots\n",
    "for feature in wholesale_customers_df.columns:\n",
    "    # Create histogram\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(wholesale_customers_df[feature], kde=True)\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # Create normal probability plot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    probplot(wholesale_customers_df[feature], plot=plt)\n",
    "    plt.title(f'Normal Probability Plot of {feature}')\n",
    "    plt.xlabel('Theoretical Quantiles')\n",
    "    plt.ylabel('Sample Quantiles')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VuXd_rFgPrO"
   },
   "source": [
    "5. What do you observe about distribution? (2 points)\n",
    "\n",
    "Based on the histograms and normal probability plots of the features in the wholesale customers dataset, we can observe the following:\n",
    "\n",
    "    1.The distributions of most features are heavily right-skewed, with a long tail towards higher values. This suggests that most customers spend relatively less on these product categories, while fewer customers have significantly higher spending.\n",
    "\n",
    "    2.Some features, such as Milk, Grocery, and Detergents_Paper, show distributions closer to normal, with a relatively symmetrical shape and no significant departure from normality in the probability plots. This indicates that these features follow a relatively normal distribution.\n",
    "\n",
    "    3.Other features, like Fresh and Frozen, show highly skewed distributions with longer tails toward higher values. This suggests that most customers have lower spending on these product categories, with a few having significantly higher spending.\n",
    "\n",
    "    4.The distributions of all features are unimodal, with a peak at lower values and a long tail towards higher values.\n",
    "\n",
    "    5.Some features show a high frequency of zero values, such as Delicatessen, which could indicate that many customers do not spend on these product categories.\n",
    "\n",
    "Overall, the distributions of the features in the wholesale customers dataset could be more perfectly normal and exhibit significant skewness. This suggests that careful consideration should be taken when choosing appropriate statistical methods and models for analyzing this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ov4OTKllgxMm"
   },
   "source": [
    "6. Scale the sample data using the natural logarithm ( 1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T17:10:28.892773Z",
     "start_time": "2018-01-03T17:10:28.868660Z"
    },
    "id": "4qwfGhObY9Rs"
   },
   "outputs": [],
   "source": [
    "# Scale the data using the natural logarithm\n",
    "wholesale_customers_df_log = np.log(wholesale_customers_df)\n",
    "\n",
    "# Print out the first few rows of the scaled data\n",
    "print(wholesale_customers_df_log.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgXuDjy6Y9Rs"
   },
   "source": [
    "7. Check for Outliers using boxplot ( 2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T17:23:35.742049Z",
     "start_time": "2018-01-03T17:23:35.387142Z"
    },
    "id": "4EzHxzioY9Rs"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wholesale_customers_df_log.boxplot()\n",
    "\n",
    "# Set the title and labels for the boxplot\n",
    "plt.title('Boxplot of Wholesale Customers Data (Log Scaled)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Log Scaled Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsfUPldMY9Rt"
   },
   "source": [
    "8. Apply natural log to transform long tails and plot the Log Sales Distribution using violinplot (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T00:25:46.809372Z",
     "start_time": "2018-01-09T00:25:46.801858Z"
    },
    "id": "HFGfqobgY9Rt"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wholesale_customers_df_log = np.log(wholesale_customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T00:25:48.120698Z",
     "start_time": "2018-01-09T00:25:47.688194Z"
    },
    "id": "QbP-SwVjY9Ru"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "sns.violinplot(data=wholesale_customers_df_log)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Logarithmic Scale')\n",
    "plt.title('Distribution of Features (Logarithmic Scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTTUDaYiY9Ru"
   },
   "source": [
    "9. Remove Outliers using LocalOutlierFactor and plot the Log Sales Distribution using violinplot after removing the outliers. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T00:25:53.467056Z",
     "start_time": "2018-01-09T00:25:53.009368Z"
    },
    "id": "4EjMvELnY9Ru"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "outliers = lof.fit_predict(wholesale_customers_df_log)\n",
    "outliers_mask = outliers == 1  # Mask to keep non-outliers\n",
    "\n",
    "# Remove outliers from the log-scaled data\n",
    "wholesale_customers_df_log_no_outliers = wholesale_customers_df_log[outliers_mask]\n",
    "\n",
    "# Plot the distribution using violinplot after removing outliers\n",
    "sns.violinplot(data=wholesale_customers_df_log_no_outliers)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Logarithmic Scale')\n",
    "plt.title('Distribution of Features (Logarithmic Scale) without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTQfRuqnnlqP"
   },
   "source": [
    "10. use sns.pairplot to visualize Feature Distributions in your cleaned data (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T00:26:09.478209Z",
     "start_time": "2018-01-09T00:26:03.113570Z"
    },
    "id": "TsvNguxrY9Rv"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "sns.pairplot(wholesale_customers_df_log_no_outliers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtlvfcy0oJP2"
   },
   "source": [
    "11. Check for Correlations using sns.clustermap (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T17:51:17.695669Z",
     "start_time": "2018-01-03T17:51:17.115826Z"
    },
    "id": "WVeUwRwOY9Rv"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "corr_matrix = wholesale_customers_df_log_no_outliers.corr()\n",
    "\n",
    "# Use sns.clustermap to visualize the correlation matrix\n",
    "sns.clustermap(corr_matrix, cmap='coolwarm', annot=True, \n",
    "               row_cluster=True, col_cluster=True, \n",
    "               method='complete', metric='euclidean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaDQtJENonfo"
   },
   "source": [
    "12. What do you observe? (2 points)\n",
    "\n",
    "After visualizing the correlations using a clustered heatmap, we can make several observations:\n",
    "\n",
    "    1.Some features show strong positive correlations, such as \"Milk\" and \"Grocery\", \"Milk\" and \"Detergents_Paper\", and \"Grocery\" and \"Detergents_Paper\". This suggests that as the spending on one of these features increases, the spending on the other features also tends to increase, indicating a potential association or dependency between these features.\n",
    "    \n",
    "    2.Some features show negative correlations, such as \"Fresh\" and \"Detergents_Paper\", and \"Frozen\" and \"Delicatessen\". This suggests that as the spending on one of these features increases, the spending on the other features tends to decrease, indicating a potential inverse relationship or trade-off between these features.\n",
    "    \n",
    "    3.Some other features show weak or no significant correlations with other features, such as \"Fresh\" and \"Grocery\", \"Frozen\" and \"Grocery\", \"Frozen\" and \"Detergents_Paper\", and \"Delicatessen\" with most other features. This suggests that these features may be relatively independent of the other features in terms of spending patterns.\n",
    "\n",
    "\n",
    "Overall, the clustered heatmap provides a visual representation of the correlations between different features in the cleaned wholesale customers data, allowing us to identify potential relationships and dependencies among the features, which can be helpful for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qvdRmo3o94w"
   },
   "source": [
    "### PCA\n",
    "Now that the data has been scaled to a more normal distribution and has had any necessary outliers removed, we can now apply PCA to the cleaned data to discover which dimensions about the data best maximize the variance of features involved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aow-OTm8Y9Rv"
   },
   "source": [
    "13. Biplot: Visualizing Product Relationships in 2D (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yd0sVx_xY9Rv"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "pca = PCA(n_components=2)\n",
    "wholesale_customers_df_log_no_outliers_pca = pca.fit_transform(wholesale_customers_df_log_no_outliers)\n",
    "\n",
    "# Create a biplot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.scatter(wholesale_customers_df_log_no_outliers_pca[:, 0], wholesale_customers_df_log_no_outliers_pca[:, 1], alpha=0.5)\n",
    "\n",
    "# Add feature loadings as arrows\n",
    "for i, feature in enumerate(wholesale_customers_df_log_no_outliers.columns):\n",
    "    ax.arrow(0, 0, pca.components_[0, i], pca.components_[1, i],\n",
    "             head_width=0.2, head_length=0.2, fc='red', ec='red')\n",
    "    ax.text(pca.components_[0, i] * 1.2, pca.components_[1, i] * 1.2,\n",
    "            feature, color='red')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('Biplot: Product Relationships in 2D')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpS5TE22rep3"
   },
   "source": [
    "14. Use sns.jointplot to plot x and y in the above code (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjVBuPnPY9Rw"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "pca = PCA(n_components=2)\n",
    "wholesale_customers_df_log_no_outliers_pca = pca.fit_transform(wholesale_customers_df_log_no_outliers)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.jointplot(wholesale_customers_df_log_no_outliers_pca[:, 0], wholesale_customers_df_log_no_outliers_pca[:, 1], kind=\"scatter\", height=8, alpha=0.5)\n",
    "\n",
    "# Add feature loadings as arrows\n",
    "for i, feature in enumerate(wholesale_customers_df_log_no_outliers.columns):\n",
    "    g.ax_joint.arrow(0, 0, pca.components_[0, i], pca.components_[1, i],\n",
    "                     head_width=0.2, head_length=0.2, fc='red', ec='red')\n",
    "    g.ax_joint.text(pca.components_[0, i] * 1.2, pca.components_[1, i] * 1.2,\n",
    "                    feature, color='red')\n",
    "\n",
    "# Set labels and title\n",
    "g.ax_joint.set_xlabel('PC1')\n",
    "g.ax_joint.set_ylabel('PC2')\n",
    "g.ax_joint.set_title('Biplot: Product Relationships in 2D')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djAr92bOY9Rw"
   },
   "source": [
    "15. Exploring the new Descriptors of the cleand Data using plot.bar (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-03T17:54:14.727601Z",
     "start_time": "2018-01-03T17:54:14.195007Z"
    },
    "id": "hkJ86sB8Y9Rw"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wholesale_customers_df_log_no_outliers.describe().plot.bar(rot=0, figsize=(10, 6), legend=False)\n",
    "plt.title(\"Descriptors of Cleaned Wholesale Customers Data\")\n",
    "plt.xlabel(\"Descriptors\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variances = pca.explained_variance_ratio_\n",
    "\n",
    "# Print the explained variance for first and second principal components\n",
    "print(\"Explained Variance Ratio for First Principal Component: {:.2%}\".format(explained_variances[0]))\n",
    "print(\"Explained Variance Ratio for Second Principal Component: {:.2%}\".format(explained_variances[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXkjQDNos9Ds",
    "tags": []
   },
   "source": [
    "16. How much approximately the first and second features of explain of variance in total? (1 point)\n",
    "\n",
    "-> Variance for First feature in total is 46.62% or 0.4662.\n",
    "\n",
    "-> Variance for Second feature in total is 27.12% or 0.2712."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-iskuujgGlC"
   },
   "source": [
    "---\n",
    "## All set\n",
    "\n",
    "Please make sure you execute each cell before you submit your file; this is important because if your code didn't work on our machine for an unknown reason, it would be better to see the result rather than losing some points or wasting time to contact you to fix this issue. \n",
    "\n",
    "What to submit:\n",
    "\n",
    "* Your Jupyter Notebook file.\n",
    "* Name your file as firstname_lastname_pj_3 . \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
